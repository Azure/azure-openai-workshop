{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2022-12-01\"\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\").strip()\n",
    "assert API_KEY, \"ERROR: Azure OpenAI Key is missing\"\n",
    "openai.api_key = API_KEY\n",
    "\n",
    "RESOURCE_ENDPOINT = os.getenv(\"OPENAI_API_BASE\",\"\").strip()\n",
    "assert RESOURCE_ENDPOINT, \"ERROR: Azure OpenAI Endpoint is missing\"\n",
    "assert \"openai.azure.com\" in RESOURCE_ENDPOINT.lower(), \"ERROR: Azure OpenAI Endpoint should be in the form: \\n\\n\\t<your unique endpoint identifier>.openai.azure.com\"\n",
    "openai.api_base = RESOURCE_ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dependencies \n",
      "| project name, resultCode\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  engine=os.getenv('DEPLOYMENT_NAME'),\n",
    "  prompt=\"Write a Kusto query to show name and resultCode columns from dependencies table.\\nAnswer:  \",\n",
    "   max_tokens=250,\n",
    "  stop=[\"#\",\";\"])\n",
    "\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'signed_session'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m      8\u001b[0m query \u001b[39m=\u001b[39m \u001b[39m'''\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[39mAmlDataSetEvent\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[39m| where split(OperationName, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m)[-1]==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mREAD\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m and AmlDatasetId !=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[39m| extend  Identity=(parse_json(Identity))\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[39m| project AmlDatasetId, UserName=Identity.UserName\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[39m| summarize  Count=count() by AmlDatasetId, UserName=tostring(UserName)\u001b[39m\u001b[39m'''\u001b[39m\n\u001b[1;32m     14\u001b[0m body \u001b[39m=\u001b[39m QueryBody(query\u001b[39m=\u001b[39mquery)\n\u001b[0;32m---> 16\u001b[0m response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mquery(workspace_id, body)\n\u001b[1;32m     17\u001b[0m results \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mtables[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mrows\n\u001b[1;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m result \u001b[39min\u001b[39;00m results:\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/loganalytics/log_analytics_data_client.py:116\u001b[0m, in \u001b[0;36mLogAnalyticsDataClient.query\u001b[0;34m(self, workspace_id, body, custom_headers, raw, **operation_config)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39m# Construct and send request\u001b[39;00m\n\u001b[1;32m    115\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39mpost(url, query_parameters)\n\u001b[0;32m--> 116\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49msend(\n\u001b[1;32m    117\u001b[0m     request, header_parameters, body_content, stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moperation_config)\n\u001b[1;32m    119\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m200\u001b[39m]:\n\u001b[1;32m    120\u001b[0m     \u001b[39mraise\u001b[39;00m models\u001b[39m.\u001b[39mErrorResponseException(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deserialize, response)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/msrest/service_client.py:336\u001b[0m, in \u001b[0;36mServiceClient.send\u001b[0;34m(self, request, headers, content, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m'\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    335\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 336\u001b[0m     pipeline_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mpipeline\u001b[39m.\u001b[39;49mrun(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    337\u001b[0m     \u001b[39m# There is too much thing that expects this method to return a \"requests.Response\"\u001b[39;00m\n\u001b[1;32m    338\u001b[0m     \u001b[39m# to break it in a compatible release.\u001b[39;00m\n\u001b[1;32m    339\u001b[0m     \u001b[39m# Also, to be pragmatic in the \"sync\" world \"requests\" rules anyway.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m     \u001b[39m# However, attach the Universal HTTP response\u001b[39;00m\n\u001b[1;32m    341\u001b[0m     \u001b[39m# to get the streaming generator.\u001b[39;00m\n\u001b[1;32m    342\u001b[0m     response \u001b[39m=\u001b[39m pipeline_response\u001b[39m.\u001b[39mhttp_response\u001b[39m.\u001b[39minternal_response\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/msrest/pipeline/__init__.py:197\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m pipeline_request \u001b[39m=\u001b[39m Request(request, context)  \u001b[39m# type: Request[HTTPRequestType]\u001b[39;00m\n\u001b[1;32m    196\u001b[0m first_node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_impl_policies[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_impl_policies \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sender\n\u001b[0;32m--> 197\u001b[0m \u001b[39mreturn\u001b[39;00m first_node\u001b[39m.\u001b[39;49msend(pipeline_request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/msrest/pipeline/__init__.py:150\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_request(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_exception(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/msrest/pipeline/requests.py:65\u001b[0m, in \u001b[0;36mRequestsCredentialsPolicy.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m session \u001b[39m=\u001b[39m request\u001b[39m.\u001b[39mcontext\u001b[39m.\u001b[39msession\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_creds\u001b[39m.\u001b[39;49msigned_session(session)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m: \u001b[39m# Credentials does not support session injection\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     _LOGGER\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mYour credentials class does not support session injection. Performance will not be at the maximum.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'signed_session'"
     ]
    }
   ],
   "source": [
    "from azure.loganalytics import LogAnalyticsDataClient\n",
    "from azure.loganalytics.models import QueryBody\n",
    "\n",
    "workspace_id = 'a5a603ea-0972-4457-b753-56e44e8c8d80'\n",
    "client = LogAnalyticsDataClient(credentials='YOUR_CREDENTIALS')\n",
    "\n",
    "# query = \"AzureActivity | summarize count() by bin(timestamp, 1h)\"\n",
    "query = '''\n",
    "AmlDataSetEvent\n",
    "| where split(OperationName, \"/\")[-1]==\"READ\" and AmlDatasetId !=\"\"\n",
    "| extend  Identity=(parse_json(Identity))\n",
    "| project AmlDatasetId, UserName=Identity.UserName\n",
    "| summarize  Count=count() by AmlDatasetId, UserName=tostring(UserName)'''\n",
    "body = QueryBody(query=query)\n",
    "\n",
    "response = client.query(workspace_id, body)\n",
    "results = response.tables[0].rows\n",
    "\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        AmlDatasetId       UserName  Count\n",
      "0  azureml://locations/eastus2/workspaces/86d4aa3...  Louis Li (AI)      2\n",
      "1               2f24db5e-dd88-4053-b7b1-f14784178136  Louis Li (AI)      1\n",
      "2               a1bc0e1a-2b18-4243-8973-64eee4aa02a8  Louis Li (AI)      2\n",
      "3               7a033689-4421-4d43-9210-a0a67da7b4df  Louis Li (AI)      2\n",
      "4               62c10f96-4f9f-42ba-ab38-df10d8784bfa  Louis Li (AI)      1\n",
      "5  azureml://locations/eastus2/workspaces/86d4aa3...  Louis Li (AI)      1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "from azure.monitor.query import LogsQueryClient, LogsQueryStatus\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "client = LogsQueryClient(credential)\n",
    "\n",
    "query = '''\n",
    "AmlDataSetEvent\n",
    "| where split(OperationName, \"/\")[-1]==\"READ\" and AmlDatasetId !=\"\"\n",
    "| extend  Identity=(parse_json(Identity))\n",
    "| project AmlDatasetId, UserName=Identity.UserName\n",
    "| summarize  Count=count() by AmlDatasetId, UserName=tostring(UserName)'''\n",
    "\n",
    "start_time=datetime(2022, 10, 1, tzinfo=timezone.utc)\n",
    "end_time=datetime(2023, 3, 10, tzinfo=timezone.utc)\n",
    "\n",
    "try:\n",
    "    response = client.query_workspace(\n",
    "        workspace_id='a0083662-5f28-449c-9f7f-62ac8a3b7cc8',\n",
    "        query=query,\n",
    "        timespan=(start_time, end_time)\n",
    "        )\n",
    "    if response.status == LogsQueryStatus.PARTIAL:\n",
    "        error = response.partial_error\n",
    "        data = response.partial_data\n",
    "        print(error)\n",
    "    elif response.status == LogsQueryStatus.SUCCESS:\n",
    "        data = response.tables\n",
    "    for table in data:\n",
    "        df = pd.DataFrame(data=table.rows, columns=table.columns)\n",
    "        print(df)\n",
    "except HttpResponseError as err:\n",
    "    print(\"something fatal happened\")\n",
    "    print (err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import AzureOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from AzureOpenAIUtil.AzureCognitiveSearch import AzureCognitiveSearchWrapper\n",
    "load_dotenv()\n",
    "search = AzureCognitiveSearchWrapper(result_field_list=['highlights','article'], k=3)\n",
    "# Next, let's load some tools to use. Note that the `llm-math` tool uses an LLM, so we need to pass that in.\n",
    "\n",
    "llm = AzureOpenAI(temperature=0, deployment_name=os.getenv('DEPLOYMENT_NAME')) \n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Intermediate Answer\",\n",
    "        func=search.run,\n",
    "        description=''\n",
    "    )\n",
    "]\n",
    "\n",
    "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
    "agent = initialize_agent(tools, llm, agent=\"self-ask-with-search\",  verbose=True)\n",
    "\n",
    "# Now let's test it out!\n",
    "result = agent.run(\"Who are top 2 competitors for Hillary Clinton in 2020 president election? Explain the reasons.\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py310_sdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
